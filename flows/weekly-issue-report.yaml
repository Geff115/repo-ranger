id: weekly-issue-report
namespace: dev
description: "Weekly AI-powered issue analysis and decision-making"

tasks:
  - id: fetch_recent_issues
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install requests
    docker:
      image: python:3.11-slim
    outputFiles:
      - "*.json"
    script: |
      import json
      import requests
      from datetime import datetime, timedelta
      
      # Fetch issues from last 7 days
      since_date = (datetime.now() - timedelta(days=7)).isoformat()
      
      headers = {
          "Authorization": "Bearer {{ env.GITHUB_PAT }}",
          "Accept": "application/vnd.github+json"
      }
      
      response = requests.get(
          "https://api.github.com/repos/Geff115/repo-ranger/issues",
          headers=headers,
          params={"state": "all", "since": since_date}
      )
      
      issues = response.json()
      
      # Extract relevant data
      issue_data = []
      for issue in issues:
          issue_data.append({
              "title": issue["title"],
              "state": issue["state"],
              "labels": [l["name"] for l in issue.get("labels", [])],
              "created_at": issue["created_at"],
              "comments": issue["comments"],
              "body": issue.get("body", "")[:200]  # First 200 chars
          })
      
      with open('issues.json', 'w') as f:
          json.dump(issue_data, f, indent=2)
      
      print(f"Fetched {len(issue_data)} issues from the past week")
      print(f"Issue data saved to issues.json")

  - id: ai_analyze_and_report
    type: io.kestra.plugin.scripts.python.Script
    beforeCommands:
      - pip install requests
    inputFiles:
      issues.json: "{{ outputs.fetch_recent_issues.outputFiles['issues.json'] }}"
    docker:
      image: python:3.11-slim
    script: |
      import json
      import requests
      from datetime import datetime, timedelta
      
      # Read issues
      with open('issues.json', 'r') as f:
          issues_data = json.load(f)
      
      # Create prompt
      prompt = f"""You are RepoRanger AI, an expert repository analyst providing strategic insights to maintainers.

      ANALYSIS REQUIREMENTS:
      1. **Trend Analysis**: 
            - Identify patterns in issue types, affected components, and user behavior
            - Compare to previous weeks if patterns are evident
            - Highlight any emerging trends
      2. **Critical Issues**: 
            - List high-priority items needing immediate attention
            - Explain why each is critical
            - Estimate impact if left unaddressed
      3. **Root Cause Analysis**: 
            - Look for underlying problems causing multiple issues
            - Identify systemic issues vs. one-off problems
      4. **Strategic Recommendations**: 
            - Provide 3-5 specific, actionable recommendations
            - Include expected impact and effort for each
            - Prioritize by value/effort ratio
      5. **Risk Assessment**: 
            - Identify potential risks if issues are not addressed
            - Estimate likelihood and impact of each risk
      6. **Resource Allocation Suggestions**:
            - Where should the team focus their efforts this week?
            - What areas are being neglected?

      Issues data (Last 7 Days):
      {json.dumps(issues_data, indent=2)}

      Provide your analysis in clear, well-structured format with:
      - Clear section headers
      - Bullet points for lists
      - Specific examples with issue numbers
      - Data-driven insights (use numbers and percentages)
      - Action-oriented language

      Focus on being helpful, specific, and actionable rather than generic."""
      
      # Call Groq API
      groq_response = requests.post(
          "https://api.groq.com/openai/v1/chat/completions",
          headers={
              "Authorization": "Bearer {{ env.GROQ_API_KEY }}",
              "Content-Type": "application/json"
          },
          json={
              "model": "llama-3.3-70b-versatile",
              "messages": [
                  {
                      "role": "system",
                      "content": "You are RepoRanger AI, an intelligent agent that analyzes GitHub repository issues and makes strategic recommendations for maintainers. Analyze patterns, identify trends, and make actionable decisions."
                  },
                  {
                      "role": "user",
                      "content": prompt
                  }
              ],
              "temperature": 0.5,
              "max_tokens": 2000
          }
      )
      
      ai_analysis = groq_response.json()['choices'][0]['message']['content']
      
      # Post to GitHub
      github_headers = {
          "Authorization": "Bearer {{ env.GITHUB_PAT }}",
          "Accept": "application/vnd.github+json"
      }
      
      next_week = (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')
      
      issue_body = f"""# üìä Weekly RepoRanger Intelligence Report

      {ai_analysis}

      ---
      **Report Details:**
      - Generated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}
      - Next Report: {next_week}
      - Powered by RepoRanger AI Agent

      *This report was automatically generated by analyzing issue patterns and making data-driven decisions.*
      """
      
      github_response = requests.post(
          "https://api.github.com/repos/Geff115/repo-ranger/issues",
          headers=github_headers,
          json={
              "title": f"üìä Weekly Intelligence Report - {datetime.now().strftime('%B %d, %Y')}",
              "body": issue_body,
              "labels": ["report", "automated", "ai-generated"]
          }
      )
      
      print(f"Weekly report posted! Status: {github_response.status_code}")
      if github_response.status_code == 201:
          print("‚úÖ Report created successfully!")
          print(f"URL: {github_response.json()['html_url']}")
      else:
          print(f"‚ùå Error: {github_response.text}")

triggers:
  - id: weekly_schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 9 * * MON"  # Every Monday at 9 AM UTC